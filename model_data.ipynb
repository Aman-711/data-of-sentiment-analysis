{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             event_name            tweet_id              image_id  \\\n",
       " 0  california_wildfires  917791291823591425  917791291823591425_0   \n",
       " 1  california_wildfires  917791291823591425  917791291823591425_1   \n",
       " 2  california_wildfires  917793137925459968  917793137925459968_0   \n",
       " 3  california_wildfires  917793137925459968  917793137925459968_1   \n",
       " 4  california_wildfires  917793137925459968  917793137925459968_2   \n",
       " \n",
       "                                           tweet_text  \\\n",
       " 0  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
       " 1  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
       " 2  RT @KAKEnews: California wildfires destroy mor...   \n",
       " 3  RT @KAKEnews: California wildfires destroy mor...   \n",
       " 4  RT @KAKEnews: California wildfires destroy mor...   \n",
       " \n",
       "                                                image            label  \\\n",
       " 0  data_image/california_wildfires/10_10_2017/917...      informative   \n",
       " 1  data_image/california_wildfires/10_10_2017/917...  not_informative   \n",
       " 2  data_image/california_wildfires/10_10_2017/917...      informative   \n",
       " 3  data_image/california_wildfires/10_10_2017/917...      informative   \n",
       " 4  data_image/california_wildfires/10_10_2017/917...      informative   \n",
       " \n",
       "     label_text      label_image label_text_image  \n",
       " 0  informative      informative         Positive  \n",
       " 1  informative  not_informative         Negative  \n",
       " 2  informative      informative         Positive  \n",
       " 3  informative      informative         Positive  \n",
       " 4  informative      informative         Positive  ,\n",
       "              event_name            tweet_id              image_id  \\\n",
       " 0  iraq_iran_earthquake  931465546129989632  931465546129989632_0   \n",
       " 1      hurricane_harvey  905064623199719425  905064623199719425_0   \n",
       " 2       hurricane_maria  922857566220283904  922857566220283904_0   \n",
       " 3        hurricane_irma  909767231411769344  909767231411769344_0   \n",
       " 4  california_wildfires  920571592131915777  920571592131915777_0   \n",
       " \n",
       "                                           tweet_text  \\\n",
       " 0  #Iran #earthquake damage put at over 5bn pound...   \n",
       " 1  We've lost track of how many houses/families @...   \n",
       " 2  The gym above subway got destroyed. The cement...   \n",
       " 3  Famous Captive Orca Fends For Herself In Flori...   \n",
       " 4  Californiaâ€™s Sausalito Fire In Marin Capture...   \n",
       " \n",
       "                                                image            label  \\\n",
       " 0  data_image/iraq_iran_earthquake/17_11_2017/931...  not_informative   \n",
       " 1  data_image/hurricane_harvey/5_9_2017/905064623...      informative   \n",
       " 2  data_image/hurricane_maria/24_10_2017/92285756...      informative   \n",
       " 3  data_image/hurricane_irma/18_9_2017/9097672314...      informative   \n",
       " 4  data_image/california_wildfires/18_10_2017/920...      informative   \n",
       " \n",
       "     label_text      label_image label_text_image  \n",
       " 0  informative  not_informative         Negative  \n",
       " 1  informative      informative         Positive  \n",
       " 2  informative      informative         Positive  \n",
       " 3  informative  not_informative         Negative  \n",
       " 4  informative      informative         Positive  ,\n",
       "          event_name            tweet_id              image_id  \\\n",
       " 0   srilanka_floods  878185882431389696  878185882431389696_0   \n",
       " 1  hurricane_harvey  906258753707790336  906258753707790336_0   \n",
       " 2   hurricane_maria  910542719864397824  910542719864397824_0   \n",
       " 3  hurricane_harvey  906219963152785408  906219963152785408_0   \n",
       " 4   hurricane_maria  913009824195104768  913009824195104768_0   \n",
       " \n",
       "                                           tweet_text  \\\n",
       " 0  Cristofer CLEMENTE MORA now in 2nd at aguille ...   \n",
       " 1  RT @THS_College: On our way to Warrior Restora...   \n",
       " 2  Hurricane Maria batters Puerto Rico as a Cat 4...   \n",
       " 3  ZZ Top Donating ‘La Grange’ Download Sales To ...   \n",
       " 4  8am #Maria update: holding steady as a strong ...   \n",
       " \n",
       "                                                image            label  \\\n",
       " 0  data_image/srilanka_floods/23_6_2017/878185882...  not_informative   \n",
       " 1  data_image/hurricane_harvey/8_9_2017/906258753...  not_informative   \n",
       " 2  data_image/hurricane_maria/20_9_2017/910542719...      informative   \n",
       " 3  data_image/hurricane_harvey/8_9_2017/906219963...      informative   \n",
       " 4  data_image/hurricane_maria/27_9_2017/913009824...      informative   \n",
       " \n",
       "         label_text      label_image label_text_image  \n",
       " 0  not_informative  not_informative         Positive  \n",
       " 1      informative  not_informative         Negative  \n",
       " 2      informative      informative         Positive  \n",
       " 3      informative  not_informative         Negative  \n",
       " 4      informative      informative         Positive  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_train.tsv'\n",
    "dev_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_dev.tsv'\n",
    "test_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_test.tsv'\n",
    "\n",
    "# Load TSV files into DataFrames\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t')\n",
    "dev_data = pd.read_csv(dev_file_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_file_path, sep='\\t')\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "train_data.head(), dev_data.head(), test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in all datasets: 18082\n",
      "Total entries in train datasets: 13608\n",
      "Total entries in validation datasets: 2237\n",
      "Total entries in test datasets: 2237\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of entries in each dataset\n",
    "train_count = len(train_data)\n",
    "dev_count = len(dev_data)\n",
    "test_count = len(test_data)\n",
    "\n",
    "# Calculate the total number of entries\n",
    "total_entries = train_count + dev_count + test_count\n",
    "\n",
    "# Display the result\n",
    "print(f\"Total entries in all datasets: {total_entries}\")\n",
    "print(f\"Total entries in train datasets: {train_count}\")\n",
    "print(f\"Total entries in validation datasets: {dev_count}\")\n",
    "print(f\"Total entries in test datasets: {test_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - Informative: 7059, Non-Informative: 6549\n",
      "Validation Set - Informative: 1164, Non-Informative: 1073\n",
      "Test Set - Informative: 1151, Non-Informative: 1086\n"
     ]
    }
   ],
   "source": [
    "# Count the number of images classified as informative and non-informative in the training set\n",
    "train_informative = train_data['label_image'].value_counts().get('informative', 0)\n",
    "train_non_informative = train_data['label_image'].value_counts().get('not_informative', 0)\n",
    "\n",
    "# Count the number of images classified as informative and non-informative in the validation set\n",
    "dev_informative = dev_data['label_image'].value_counts().get('informative', 0)\n",
    "dev_non_informative = dev_data['label_image'].value_counts().get('not_informative', 0)\n",
    "\n",
    "# Count the number of images classified as informative and non-informative in the test set\n",
    "test_informative = test_data['label_image'].value_counts().get('informative', 0)\n",
    "test_non_informative = test_data['label_image'].value_counts().get('not_informative', 0)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Training Set - Informative: {train_informative}, Non-Informative: {train_non_informative}\")\n",
    "print(f\"Validation Set - Informative: {dev_informative}, Non-Informative: {dev_non_informative}\")\n",
    "print(f\"Test Set - Informative: {test_informative}, Non-Informative: {test_non_informative}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - Informative: 9638, Non-Informative: 3970\n",
      "Validation Set - Informative: 1612, Non-Informative: 625\n",
      "Test Set - Informative: 1612, Non-Informative: 625\n",
      "Total - Informative: 12862, Non-Informative: 5220\n"
     ]
    }
   ],
   "source": [
    "# Count the number of texts classified as informative and non-informative in the training set\n",
    "train_text_informative = train_data['label_text'].value_counts().get('informative', 0)\n",
    "train_text_non_informative = train_data['label_text'].value_counts().get('not_informative', 0)\n",
    "\n",
    "# Count the number of texts classified as informative and non-informative in the validation set\n",
    "dev_text_informative = dev_data['label_text'].value_counts().get('informative', 0)\n",
    "dev_text_non_informative = dev_data['label_text'].value_counts().get('not_informative', 0)\n",
    "\n",
    "# Count the number of texts classified as informative and non-informative in the test set\n",
    "test_text_informative = test_data['label_text'].value_counts().get('informative', 0)\n",
    "test_text_non_informative = test_data['label_text'].value_counts().get('not_informative', 0)\n",
    "\n",
    "# Calculate totals across all datasets\n",
    "total_text_informative = train_text_informative + dev_text_informative + test_text_informative\n",
    "total_text_non_informative = train_text_non_informative + dev_text_non_informative + test_text_non_informative\n",
    "\n",
    "# Display the results\n",
    "print(f\"Training Set - Informative: {train_text_informative}, Non-Informative: {train_text_non_informative}\")\n",
    "print(f\"Validation Set - Informative: {dev_text_informative}, Non-Informative: {dev_text_non_informative}\")\n",
    "print(f\"Test Set - Informative: {test_text_informative}, Non-Informative: {test_text_non_informative}\")\n",
    "print(f\"Total - Informative: {total_text_informative}, Non-Informative: {total_text_non_informative}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - Similar: 9601, Dissimilar: 4007\n",
      "Validation Set - Similar: 1573, Dissimilar: 664\n",
      "Test Set - Similar: 1534, Dissimilar: 703\n",
      "Total - Similar: 12708, Dissimilar: 5374\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate similarity and dissimilarity\n",
    "def calculate_similarity(data):\n",
    "    # Count similarly classified (same label for text and image)\n",
    "    similar = ((data['label_text'] == 'informative') & (data['label_image'] == 'informative')).sum() + \\\n",
    "              ((data['label_text'] == 'not_informative') & (data['label_image'] == 'not_informative')).sum()\n",
    "    \n",
    "    # Count dissimilarly classified (different label for text and image)\n",
    "    dissimilar = ((data['label_text'] == 'informative') & (data['label_image'] == 'not_informative')).sum() + \\\n",
    "                 ((data['label_text'] == 'not_informative') & (data['label_image'] == 'informative')).sum()\n",
    "    \n",
    "    return similar, dissimilar\n",
    "\n",
    "# Calculate for each dataset\n",
    "train_similar, train_dissimilar = calculate_similarity(train_data)\n",
    "dev_similar, dev_dissimilar = calculate_similarity(dev_data)\n",
    "test_similar, test_dissimilar = calculate_similarity(test_data)\n",
    "\n",
    "# Sum up for the total across all datasets\n",
    "total_similar = train_similar + dev_similar + test_similar\n",
    "total_dissimilar = train_dissimilar + dev_dissimilar + test_dissimilar\n",
    "\n",
    "# Display the results\n",
    "print(f\"Training Set - Similar: {train_similar}, Dissimilar: {train_dissimilar}\")\n",
    "print(f\"Validation Set - Similar: {dev_similar}, Dissimilar: {dev_dissimilar}\")\n",
    "print(f\"Test Set - Similar: {test_similar}, Dissimilar: {test_dissimilar}\")\n",
    "print(f\"Total - Similar: {total_similar}, Dissimilar: {total_dissimilar}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Results:\n",
      "Similar: 9601, Dissimilar: 4007\n",
      "Informative Similar: 6345, Non-informative Similar: 3256\n",
      "Informative Dissimilar: 3293, Non-informative Dissimilar: 714\n",
      "\n",
      "Validation Set Results:\n",
      "Similar: 1573, Dissimilar: 664\n",
      "Informative Similar: 1056, Non-informative Similar: 517\n",
      "Informative Dissimilar: 556, Non-informative Dissimilar: 108\n",
      "\n",
      "Test Set Results:\n",
      "Similar: 1534, Dissimilar: 703\n",
      "Informative Similar: 1030, Non-informative Similar: 504\n",
      "Informative Dissimilar: 582, Non-informative Dissimilar: 121\n",
      "\n",
      "Overall Results:\n",
      "Similar: 12708, Dissimilar: 5374\n",
      "Informative Similar: 8431, Non-informative Similar: 4277\n",
      "Informative Dissimilar: 4431, Non-informative Dissimilar: 943\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_train.tsv'\n",
    "dev_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_dev.tsv'\n",
    "test_file_path = 'crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_test.tsv'\n",
    "\n",
    "# Load TSV files into DataFrames\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t')\n",
    "dev_data = pd.read_csv(dev_file_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_file_path, sep='\\t')\n",
    "\n",
    "# Function to calculate similar and dissimilar labels for informative and non-informative\n",
    "def calculate_similarity(data):\n",
    "    # Similar labels (label_text == label_image)\n",
    "    similar = (data['label_text'] == data['label_image']).sum()\n",
    "    \n",
    "    # Dissimilar labels (label_text != label_image)\n",
    "    dissimilar = (data['label_text'] != data['label_image']).sum()\n",
    "\n",
    "    # Further divide into informative and non_informative counts\n",
    "    informative_similar = ((data['label_text'] == 'informative') & (data['label_image'] == 'informative')).sum()\n",
    "    non_informative_similar = ((data['label_text'] == 'not_informative') & (data['label_image'] == 'not_informative')).sum()\n",
    "    \n",
    "    informative_dissimilar = ((data['label_text'] == 'informative') & (data['label_image'] == 'not_informative')).sum()\n",
    "    non_informative_dissimilar = ((data['label_text'] == 'not_informative') & (data['label_image'] == 'informative')).sum()\n",
    "\n",
    "    return {\n",
    "        \"similar\": similar,\n",
    "        \"dissimilar\": dissimilar,\n",
    "        \"informative_similar\": informative_similar,\n",
    "        \"non_informative_similar\": non_informative_similar,\n",
    "        \"informative_dissimilar\": informative_dissimilar,\n",
    "        \"non_informative_dissimilar\": non_informative_dissimilar\n",
    "    }\n",
    "\n",
    "# Calculate results for train, dev, and test datasets\n",
    "train_results = calculate_similarity(train_data)\n",
    "dev_results = calculate_similarity(dev_data)\n",
    "test_results = calculate_similarity(test_data)\n",
    "\n",
    "# Sum up the results across all datasets\n",
    "overall_results = {\n",
    "    \"similar\": train_results['similar'] + dev_results['similar'] + test_results['similar'],\n",
    "    \"dissimilar\": train_results['dissimilar'] + dev_results['dissimilar'] + test_results['dissimilar'],\n",
    "    \"informative_similar\": train_results['informative_similar'] + dev_results['informative_similar'] + test_results['informative_similar'],\n",
    "    \"non_informative_similar\": train_results['non_informative_similar'] + dev_results['non_informative_similar'] + test_results['non_informative_similar'],\n",
    "    \"informative_dissimilar\": train_results['informative_dissimilar'] + dev_results['informative_dissimilar'] + test_results['informative_dissimilar'],\n",
    "    \"non_informative_dissimilar\": train_results['non_informative_dissimilar'] + dev_results['non_informative_dissimilar'] + test_results['non_informative_dissimilar']\n",
    "}\n",
    "\n",
    "# Display the results\n",
    "print(\"Training Set Results:\")\n",
    "print(f\"Similar: {train_results['similar']}, Dissimilar: {train_results['dissimilar']}\")\n",
    "print(f\"Informative Similar: {train_results['informative_similar']}, Non-informative Similar: {train_results['non_informative_similar']}\")\n",
    "print(f\"Informative Dissimilar: {train_results['informative_dissimilar']}, Non-informative Dissimilar: {train_results['non_informative_dissimilar']}\")\n",
    "print(\"\\nValidation Set Results:\")\n",
    "print(f\"Similar: {dev_results['similar']}, Dissimilar: {dev_results['dissimilar']}\")\n",
    "print(f\"Informative Similar: {dev_results['informative_similar']}, Non-informative Similar: {dev_results['non_informative_similar']}\")\n",
    "print(f\"Informative Dissimilar: {dev_results['informative_dissimilar']}, Non-informative Dissimilar: {dev_results['non_informative_dissimilar']}\")\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"Similar: {test_results['similar']}, Dissimilar: {test_results['dissimilar']}\")\n",
    "print(f\"Informative Similar: {test_results['informative_similar']}, Non-informative Similar: {test_results['non_informative_similar']}\")\n",
    "print(f\"Informative Dissimilar: {test_results['informative_dissimilar']}, Non-informative Dissimilar: {test_results['non_informative_dissimilar']}\")\n",
    "print(\"\\nOverall Results:\")\n",
    "print(f\"Similar: {overall_results['similar']}, Dissimilar: {overall_results['dissimilar']}\")\n",
    "print(f\"Informative Similar: {overall_results['informative_similar']}, Non-informative Similar: {overall_results['non_informative_similar']}\")\n",
    "print(f\"Informative Dissimilar: {overall_results['informative_dissimilar']}, Non-informative Dissimilar: {overall_results['non_informative_dissimilar']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
